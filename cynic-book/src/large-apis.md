# Working with Large APIs

Some APIs have fairly large schemas, and this introduces some performance
challenges for cynic.  Runtime performance should be unaffected, but it can
lead to extended compile times and make rust-analyzer less responsive than it
would otherwise be.

There's several tricks to help with this though:

### Registering Schemas with rkyv

If you're not already you should be [pre-registering your schema](./schemas.md).

You should also enable the `rkyv` feature flag in `cynic_codegen`.  This allows
the pre-registration to store schemas in an optimised format, which avoids a
lot of comparatively slow parsing.

### Splitting Crates

Definitely consider moving your schema module into a separate crate.  These
modules contain _a lot_ of generated code and are quite expensive to compile.
Moving them to a separate crate should reduce the chance that unrelated changes
cause it to recompile.  Note that you'll need to register your schema in both
the schema module crate and any crate where you use the cynic derives.

You can also consider moving your query structs into their own crate, for
reasons similar to the above.  Though it may be worth testing whether this
actually helps - with rkyv turned on these shouldn't be too slow.  But it
really depends on how many of them you have.

### Example Workspace Setup

All subheadings are clickable and lead to executable Rust crates that follow the corresponding snippets.

{{#include ../../large-api-example/README.md}}


#### [Export schema generated by `#[cynic::schema(...)]`](https://github.com/obmarg/cynic/tree/main/large-api-example/schema)

`cynic-codegen` is used in the `build.rs` to register the schema. 
Make sure to enable the `rkyv` feature flag for faster compilation! 
```rust,no_run,noplayground
{{#include ../../large-api-example/schema/build.rs}}
```

The next step is to generate and export the large GitHub GraphQL Schema from `lib.rs` as a reusable module. 
The module can be named however you like at this point, but either `schema` or an identifier related to the registered schema is recommended.
```rust,no_run,noplayground
{{#include ../../large-api-example/schema/src/lib.rs}}
```

#### [Deriving queries with `#[derive(cynic::QueryFragment)]`](https://github.com/obmarg/cynic/tree/main/large-api-example/query)

Queries require metadata generated by `cynic::register_schema`, so the same incantation used in `schema/build.rs` must be repeated for `query/build.rs`.

```rust,no_run,noplayground
{{#include ../../large-api-example/query/build.rs}}
```

Next, create a `lib.rs` file within the `query` crate that begins with the following lines.

```rust,no_run,noplayground
use cynic; // Import for derive macros
use schema::github as schema; // Rename is vital! Must import as schema!
```

As indicated by the second comment, when importing the codegenned schema from its crate, its module must be named `schema`, otherwise the upcoming `#[derive(cynic::QueryFragment)]` macro applications will fail.
The remainder of this file shall contain exportable structs as output by [`cynic querygen`](./derives/index.md).


#### [Sending GraphQL queries](https://github.com/obmarg/cynic/tree/main/large-api-example/api)

Now that both the schema and queries are cached as separate crates, an application can make use of these by using the `query` crate to run queries.

```rust,no_run,noplayground
{{#include ../../large-api-example/api/src/main.rs:1:10}}
fn run_query() -> cynic::GraphQlResponse<PullRequestTitles> {
    ...
}
```